{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5707c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    f1_score, hinge_loss, precision_score, recall_score )\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f564ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed_data.csv file\n",
    "data_selected = pd.read_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98eae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year             0\n",
      "Dis Mag Scale    0\n",
      "Dis Mag Value    0\n",
      "Country          0\n",
      "Longitude        0\n",
      "Latitude         0\n",
      "Disaster Type    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in the new csv file\n",
    "print(data_selected.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03262d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     5551\n",
      "12    4496\n",
      "2     1544\n",
      "3     1501\n",
      "10     776\n",
      "1      770\n",
      "4      603\n",
      "14     471\n",
      "13     265\n",
      "9       96\n",
      "11      48\n",
      "7        2\n",
      "6        1\n",
      "8        1\n",
      "0        1\n",
      "Name: Disaster Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking the class distribution\n",
    "print(data_selected['Disaster Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b640565f",
   "metadata": {},
   "source": [
    "#### Our data is not balanced, so to balance our data we are using Random Oversampler Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bece9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating feature set and target variable\n",
    "X = data_selected.drop('Disaster Type', axis=1)\n",
    "y = data_selected['Disaster Type']\n",
    "\n",
    "# Initializing the RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fitting and applying the oversampling\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fd499a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     5551\n",
      "2     5551\n",
      "13    5551\n",
      "11    5551\n",
      "12    5551\n",
      "5     5551\n",
      "3     5551\n",
      "10    5551\n",
      "14    5551\n",
      "4     5551\n",
      "6     5551\n",
      "9     5551\n",
      "8     5551\n",
      "0     5551\n",
      "7     5551\n",
      "Name: Disaster Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking the new class distribution\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5326e9f9",
   "metadata": {},
   "source": [
    "#### Now as we have a balanced data, we are processing from step 4 (model development) again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7501af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 0.953822134150003\n",
      "\n",
      "\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "Accuracy: 0.6500330270822074\n",
      "\n",
      "\n",
      "\n",
      "K-Nearest Neighbors (KNN):\n",
      "Accuracy: 0.9306431273644389\n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy: 0.6532156368221942\n"
     ]
    }
   ],
   "source": [
    "# Splitting the resampled dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing/Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Training the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation the Random Forest model\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print('\\n')\n",
    "\n",
    "# Training the Support Vector Machine (SVM)\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation the SVM model\n",
    "print(\"\\nSupport Vector Machine (SVM):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print('\\n')\n",
    "\n",
    "# Training the K-Nearest Neighbors (KNN)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation the KNN model\n",
    "print(\"\\nK-Nearest Neighbors (KNN):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print('\\n')\n",
    "\n",
    "# Training the Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation the Naive Bayes model\n",
    "print(\"\\nNaive Bayes:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb5daa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Evaluation Metrics:\n",
      "F1 Score: 0.9519389979386549\n",
      "Accuracy: 0.953822134150003\n",
      "Recall (Sensitivity): 0.953822134150003\n",
      "Precision: 0.9551815103634058\n",
      "\n",
      "\n",
      "Support Vector Machine (SVM)-Evaluation Metrics:\n",
      "F1 Score: 0.633872977472952\n",
      "Accuracy: 0.6500330270822074\n",
      "Recall (Sensitivity): 0.6500330270822074\n",
      "Precision: 0.6828630625480667\n",
      "\n",
      "\n",
      "K-Nearest Neighbor (K-NN)-Evaluation Metrics:\n",
      "F1 Score: 0.9251906691254912\n",
      "Accuracy: 0.9306431273644389\n",
      "Recall (Sensitivity): 0.9306431273644389\n",
      "Precision: 0.9316988724025791\n",
      "\n",
      "\n",
      "Navie Bayes-Evaluation Metrics:\n",
      "F1 Score: 0.6297211670429899\n",
      "Accuracy: 0.6532156368221942\n",
      "Recall (Sensitivity): 0.6532156368221942\n",
      "Precision: 0.7167261979602237\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance of Random Forest\n",
    "print(\"Random Forest Classifier Evaluation Metrics:\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf, average='weighted'))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Recall (Sensitivity):\", recall_score(y_test, y_pred_rf, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf, average='weighted'))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Evaluating the performance of SVM\n",
    "print(\"Support Vector Machine (SVM)-Evaluation Metrics:\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_svm, average='weighted'))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Recall (Sensitivity):\", recall_score(y_test, y_pred_svm, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm, average='weighted'))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Evaluating the performance of K-NN\n",
    "print(\"K-Nearest Neighbor (K-NN)-Evaluation Metrics:\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_knn, average='weighted'))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Recall (Sensitivity):\", recall_score(y_test, y_pred_knn, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_knn, average='weighted'))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Evaluating the performance of Navie Bayes\n",
    "print(\"Navie Bayes-Evaluation Metrics:\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_nb, average='weighted'))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Recall (Sensitivity):\", recall_score(y_test, y_pred_nb, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_nb, average='weighted'))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce51e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Model (Hard Voting):\n",
      "F1 Score: 0.918754273334802\n",
      "Accuracy: 0.9228967753557917\n",
      "Recall (Sensitivity): 0.9228967753557917\n",
      "Precision: 0.9292699366964609\n"
     ]
    }
   ],
   "source": [
    "# Combining individual models to form a Ensemble Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Creating a hard voting classifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),\n",
    "    ('svm', svm_model),\n",
    "    ('knn', knn_model),\n",
    "    ('nb', nb_model)\n",
    "], voting='hard')\n",
    "\n",
    "# Fitting the ensemble model\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "print(\"\\nEnsemble Model (Hard Voting):\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_ensemble, average='weighted'))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
    "print(\"Recall (Sensitivity):\", recall_score(y_test, y_pred_ensemble, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_ensemble, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc607c7",
   "metadata": {},
   "source": [
    "## Performing Ensemble Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef838a",
   "metadata": {},
   "source": [
    "### Hard voting Ensemble combining 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b416d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Model (Hard Voting):\n",
      "F1 Score: 0.918754273334802\n",
      "Accuracy: 0.9228967753557917\n",
      "Recall (Sensitivity): 0.9228967753557917\n",
      "Precision: 0.9292699366964609\n"
     ]
    }
   ],
   "source": [
    "# Combining individual models to form a Ensemble Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Creating a hard voting classifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),\n",
    "    ('svm', svm_model),\n",
    "    ('knn', knn_model),\n",
    "    ('nb', nb_model)\n",
    "], voting='hard')\n",
    "\n",
    "# Fitting the ensemble model\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "print(\"\\nEnsemble Model (Hard Voting):\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_ensemble, average='weighted'))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
    "print(\"Recall (Sensitivity):\", recall_score(y_test, y_pred_ensemble, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_ensemble, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a5622",
   "metadata": {},
   "source": [
    "### Soft voting ensemble for svm and random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d7a4da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Model (Soft Voting):\n",
      "F1 Score: 0.9352540236961946\n",
      "Accuracy: 0.9392301687383655\n",
      "Recall (Sensitivity): 0.9392301687383655\n",
      "Precision: 0.9433715392610226\n"
     ]
    }
   ],
   "source": [
    "# Combining individual models with probability estimates to form an Ensemble Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_model = SVC(kernel='linear', C=1.0, probability=True, random_state=42)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Creating a soft voting classifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('rf', rf_model),\n",
    "    ('svm', svm_model),\n",
    "    ('knn', knn_model),\n",
    "    ('nb', nb_model)\n",
    "], voting='soft')\n",
    "\n",
    "# Fitting the ensemble model\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "print(\"\\nEnsemble Model (Soft Voting):\")\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_ensemble, average='weighted'))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
    "print(\"Recall (Sensitivity):\", recall_score(y_test, y_pred_ensemble, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_ensemble, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
